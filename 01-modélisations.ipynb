{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eeekon/anaconda3/lib/python3.11/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Importations de bibliothèques standard\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Configuration du chemin pour les importations\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.ensemble import EasyEnsembleClassifier, BalancedRandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, auc, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.functions import *\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Dossier pour sauvegarder les checkpoints\n",
    "checkpoint_dir = \"../models/checkpoints/\"\n",
    "\n",
    "# Créer le dossier si non existant\n",
    "os.makedirs(checkpoint_dir, existant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.functions \n",
    "importlib.reload(utils.functions)\n",
    "\n",
    "from utils.functions import *  # Cela mettra à jour les définitions de fonctions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 - Les données\n",
    "\n",
    "**Données** : \"Credit Card Fraud Detection\"<br> \n",
    "**Dimensions des données** : L'ensemble de données comprend 284,807 lignes et 31 colonnes. Les variables sont les suivantes : \n",
    "\n",
    "- **Time** : Nombre de secondes écoulées depuis la première transaction dans l'ensemble de données.\n",
    "- **V1, V2, ..., V28** : Caractéristiques techniques résultant d'une ACP (Analyse en Composantes Principales) pour protéger la confidentialité des données.\n",
    "- **Amount** : Montant de la transaction.\n",
    "- **Class** : Classe cible où 1 représente une transaction frauduleuse et 0 une transaction non frauduleuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation de la données\n",
    "data = pd.read_csv(\"../data/creditcard.csv.gz\", compression=\"gzip\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Préparation des données pour la modélisation.\n",
    "### 1.1.1 Robust scaler sur l'Amount\n",
    "En cas de présence de valeurs aberrantes, l'utilisation du RobustScaler permet de réduire leurs impacts sur la normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy().drop(columns=\"Time\")\n",
    "y = X.pop(\"Class\").to_numpy()\n",
    "rs = RobustScaler().fit(X[['Amount']])\n",
    "X[['Amount']] = rs.transform(X[['Amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2 - Séparation des données en données d'apprentissage et données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repartition des transactions dans les données d'entrainements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.998271\n",
       "1    0.001729\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repartition des transactions dans les données de test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.99828\n",
       "1    0.00172\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"repartition des transactions dans les données d'entrainements\")\n",
    "display(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(\"repartition des transactions dans les données de test\")\n",
    "pd.Series(y_test).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La proportion des transactions frauduleuses ou non est respectée dans les données d'entrainement et les données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Modélisation avec la Regression Logistique\n",
    "## 2.1  1er modele, Regression Logistique\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved in ../models/models_fitted/RL_01.pkl\n"
     ]
    }
   ],
   "source": [
    "RL = LogisticRegression(random_state=42, max_iter=1000, class_weight=\"balanced\")\n",
    "RL.fit(X_train, y_train)\n",
    "save_final_model(\"../models/models_fitted/\", \"RL_01\", {\"RL_01\" : RL})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Variation des poids de la classe minoritaire et effet sur le modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved in ../models/models_fitted/LR_with_weight_fitted.pkl\n"
     ]
    }
   ],
   "source": [
    "LR_with_weight_fitted = {}\n",
    "weights=[2,3,4,5,7,10,15,20,50,100,500]\n",
    "\n",
    "for p in weights : \n",
    "    class_weight = {0:1, 1:p}\n",
    "    RL = LogisticRegression(random_state=42, max_iter=1000, class_weight=class_weight)\n",
    "    RL.fit(X_train, y_train)\n",
    "    LR_with_weight_fitted[\"LR_{}\".format(class_weight)] = RL\n",
    "\n",
    "save_final_model(\"../models/models_fitted/\", \"LR_with_weight_fitted\", LR_with_weight_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Autres modeles robustes aux données déséquilibrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0,random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, verbose=-1),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"BalancedRandomForest\": BalancedRandomForestClassifier(random_state=42),\n",
    "    \"EasyEnsemble\": EasyEnsembleClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Définir les grilles de paramètres\n",
    "param_grids = {\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "            },\n",
    "    \"SVM\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "            },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200,500],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 6, 10]\n",
    "                },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [100, 200,500],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'depth': [3, 6, 10]\n",
    "                },\n",
    "    \"LightGBM\": {\n",
    "        'n_estimators': [100, 200,500],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 6, 10]\n",
    "                },\n",
    "    \"RandomForest\": {\n",
    "        'n_estimators': [100, 200,500],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "                },\n",
    "    \"BalancedRandomForest\": {\n",
    "        'n_estimators': [100, 200,500],\n",
    "        'max_depth': [None, 10, 20]\n",
    "                },\n",
    "    \"EasyEnsemble\": {\n",
    "        'n_estimators': [50, 100,500]\n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from ../models/checkpoints/various_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/various_models_fitted_with_best_parameters_results.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 59283.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has already been trained. Skipping.\n",
      "SVM has already been trained. Skipping.\n",
      "XGBoost has already been trained. Skipping.\n",
      "CatBoost has already been trained. Skipping.\n",
      "LightGBM has already been trained. Skipping.\n",
      "RandomForest has already been trained. Skipping.\n",
      "BalancedRandomForest has already been trained. Skipping.\n",
      "EasyEnsemble has already been trained. Skipping.\n",
      "End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved in ../models/models_fitted/various_models_fitted_with_best_parameters.pkl\n"
     ]
    }
   ],
   "source": [
    "model_name_in_folder = \"various_models_fitted_with_best_parameters\"\n",
    "models_fitted, results = load_checkpoint_model(checkpoint_dir=checkpoint_dir, model_name_in_folder=model_name_in_folder)\n",
    "\n",
    "\n",
    "for model_name, model in tqdm(models.items()):\n",
    "    if model_name in models_fitted:\n",
    "        print(f\"{model_name} has already been trained. Skipping.\")\n",
    "        # Charger le modèle entraîné depuis le dictionnaire\n",
    "        continue  # On passe au modèle suivant\n",
    "    \n",
    "    print(f\"Searching for best parameters for {model_name}...\") \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=5, n_jobs=-1, verbose=1, scoring=\"f1\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    results[model_name] = grid_search.best_params_, grid_search.best_score_\n",
    "    models_fitted[model_name] = grid_search.best_estimator_ \n",
    "\n",
    "    save_checkpoint(checkpoint_dir, model_name_in_folder, models_fitted, results)\n",
    "print(\"End\")\n",
    "# Sauvegarde finale du dictionnaire des modèles\n",
    "save_final_model(\"../models/models_fitted/\", model_name_in_folder, models_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Best Params: {'n_neighbors': 3, 'weights': 'distance'}, Best Score: 0.8430\n",
      "SVM: Best Params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}, Best Score: 0.8285\n",
      "XGBoost: Best Params: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 500}, Best Score: 0.8647\n",
      "CatBoost: Best Params: {'depth': 6, 'iterations': 500, 'learning_rate': 0.2}, Best Score: 0.8652\n",
      "LightGBM: Best Params: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}, Best Score: 0.8443\n",
      "RandomForest: Best Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}, Best Score: 0.8435\n",
      "BalancedRandomForest: Best Params: {'max_depth': 10, 'n_estimators': 200}, Best Score: 0.1132\n",
      "EasyEnsemble: Best Params: {'n_estimators': 50}, Best Score: 0.0901\n"
     ]
    }
   ],
   "source": [
    "# Affichage des résultats\n",
    "for model_name, (best_params, best_score) in results.items():\n",
    "    print(f\"{model_name}: Best Params: {best_params}, Best Score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Techniques d'Ensemble learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final models loaded from ../models/models_fitted/various_models_fitted_with_best_parameters.pkl \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Charger les modèles\n",
    "Various_models = load_final_model(\"../models/models_fitted/\", 'various_models_fitted_with_best_parameters')\n",
    "\n",
    "# Calculer les métriques\n",
    "models_pr_dict_VM = {}\n",
    "for model_name, model in Various_models.items(): \n",
    "    models_pr_dict_VM[model_name] = calculate_metrics(model, X_test, y_test)\n",
    "\n",
    "# 1. Trier les modèles par AUC-PR puis par F1\n",
    "sorted_models = sorted(\n",
    "    models_pr_dict_VM.items(),\n",
    "    key=lambda item: (-item[1]['auc_pr'], -item[1]['f1'])\n",
    ")\n",
    "\n",
    "# 2. Prendre les 4 meilleurs modèles\n",
    "top_models_metrics = dict(sorted_models[:4])  # Dictionnaire des métriques des 4 meilleurs\n",
    "top_model_names = list(top_models_metrics.keys())  # Liste des noms des 4 meilleurs modèles\n",
    "\n",
    "# 3. Récupérer les modèles correspondants depuis Various_models\n",
    "top_models = {name: Various_models[name] for name in top_model_names}\n",
    "\n",
    "# 4. Prendre le 5ème meilleur modèle comme final_estimator\n",
    "final_estimator_name = sorted_models[4][0]  # Le nom du 5ème modèle\n",
    "final_estimator = Various_models[final_estimator_name]  # Récupérer le modèle lui-même\n",
    "\n",
    "# Modèles d'ensemble avec les meilleurs modèles\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[(name, model) for name, model in top_models.items()],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[(name, model) for name, model in top_models.items()],\n",
    "    final_estimator=final_estimator  # Utiliser le 5e meilleur modèle\n",
    ")\n",
    "\n",
    "# Dictionnaire des modèles d'ensemble\n",
    "ensemble_models = {\n",
    "    'Voting': voting_model,\n",
    "    'Stacking': stacking_model\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from ../models/checkpoints/ensemble_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/ensemble_models_fitted_with_best_parameters_results.pkl\n",
      "Voting has already been trained. Skipping.\n",
      "Stacking has already been trained. Skipping.\n",
      "Models saved in ../models/models_fitted/ensemble_models_fitted_with_best_parameters.pkl\n"
     ]
    }
   ],
   "source": [
    "model_name_in_folder = \"ensemble_models_fitted_with_best_parameters\"\n",
    "ensemble_models_fitted, models_pr_dict_ensemble = load_checkpoint_model(checkpoint_dir=checkpoint_dir, model_name_in_folder=model_name_in_folder)\n",
    "\n",
    "for model_name, model in ensemble_models.items():\n",
    "    if model_name in models_pr_dict_ensemble:\n",
    "        print(f\"{model_name} has already been trained. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    models_pr_dict_ensemble[model_name] = calculate_metrics(model, X_test, y_test)\n",
    "    ensemble_models_fitted[model_name] = model\n",
    "    print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Sauvegarder les checkpoints après chaque modèle\n",
    "    save_checkpoint(checkpoint_dir, model_name_in_folder, ensemble_models_fitted, models_pr_dict_ensemble)\n",
    "\n",
    "# Sauvegarde finale du dictionnaire des modèles\n",
    "save_final_model(\"../models/models_fitted/\", model_name_in_folder, ensemble_models_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Réchantillonnage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4920\n",
       "1     492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "pd.Series(y_rus).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3444\n",
      "1     344\n",
      "Name: count, dtype: int64\n",
      "0    1476\n",
      "1     148\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus,y_rus, train_size=0.7, random_state=42, stratify=y_rus)\n",
    "print(pd.Series(y_train_rus).value_counts())\n",
    "print(pd.Series(y_test_rus).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X.copy()\n",
    "df['Class'] = y\n",
    "\n",
    "# Appliquez le sous-échantillonnage\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus,y_rus, train_size=0.7, random_state=42)\n",
    "#pd.Series(y_train_).value_counts()\n",
    "\n",
    "# Créez DataFrames à partir des résultats du sous-échantillonnage\n",
    "df_rus = pd.DataFrame(X_rus, columns=X.columns)\n",
    "df_rus['Class'] = y_rus\n",
    "\n",
    "# Conservez les indices des données retenues\n",
    "indices_retained = df_rus.index\n",
    "\n",
    "# Identifiez les indices non retenus\n",
    "indices_non_retenus = np.setdiff1d(df.index, indices_retained)\n",
    "\n",
    "# Créez le DataFrame des exemples non retenus\n",
    "df_non_retenus = df.loc[indices_non_retenus]\n",
    "\n",
    "# Séparez les caractéristiques et les labels pour les exemples non retenus\n",
    "X_not_retained = df_non_retenus.drop(columns='Class')\n",
    "y_not_retained = df_non_retenus['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from ../models/checkpoints/RUS_01_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/RUS_01_models_fitted_with_best_parameters_results.pkl\n",
      "KNN has already been trained. Loading from the dictionary.\n",
      "SVM has already been trained. Loading from the dictionary.\n",
      "XGBoost has already been trained. Loading from the dictionary.\n",
      "CatBoost has already been trained. Loading from the dictionary.\n",
      "LightGBM has already been trained. Loading from the dictionary.\n",
      "RandomForest has already been trained. Loading from the dictionary.\n",
      "Models saved in ../models/models_fitted/RUS_01_models_fitted_with_best_parameters.pkl\n"
     ]
    }
   ],
   "source": [
    "# Initialiser un dictionnaire vide pour stocker les modèles entraînés\n",
    "\n",
    "model_name_in_folder = \"RUS_01_models_fitted_with_best_parameters\"\n",
    "\n",
    "# Charger les modèles et résultats sauvegardés\n",
    "trained_models_rus, models_pr_dict_RUS = load_checkpoint_model(checkpoint_dir=checkpoint_dir, model_name_in_folder=model_name_in_folder)\n",
    "\n",
    "# Dictionnaire contenant les modèles avant entraînement\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0,random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, verbose=-1),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Boucle d'entraînement des modèles\n",
    "for model_name, model in models.items():\n",
    "    if model_name in trained_models_rus :\n",
    "        print(f\"{model_name} has already been trained. Loading from the dictionary.\")\n",
    "        continue \n",
    "\n",
    "    model.fit(X_train_rus, y_train_rus)\n",
    "    y_pred_rus = model.predict(X_test_rus)\n",
    "    \n",
    "    trained_models_rus[model_name] = model\n",
    "    models_pr_dict_RUS[model_name] = calculate_metrics(model, X_test_rus, y_test_rus)\n",
    "\n",
    "    save_checkpoint(checkpoint_dir, model_name_in_folder, trained_models_rus, models_pr_dict_RUS)\n",
    "\n",
    "# Sauvegarde finale du dictionnaire des modèles\n",
    "save_final_model(\"../models/models_fitted/\", model_name_in_folder, trained_models_rus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_results.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:00, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has already been trained with sampling strategy 0.1. Skipping.\n",
      "SVM has already been trained with sampling strategy 0.1. Skipping.\n",
      "XGBoost has already been trained with sampling strategy 0.1. Skipping.\n",
      "CatBoost has already been trained with sampling strategy 0.1. Skipping.\n",
      "LightGBM has already been trained with sampling strategy 0.1. Skipping.\n",
      "RandomForest has already been trained with sampling strategy 0.1. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 33.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully at ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_results.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 88.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has already been trained with sampling strategy 0.2. Skipping.\n",
      "SVM has already been trained with sampling strategy 0.2. Skipping.\n",
      "XGBoost has already been trained with sampling strategy 0.2. Skipping.\n",
      "CatBoost has already been trained with sampling strategy 0.2. Skipping.\n",
      "LightGBM has already been trained with sampling strategy 0.2. Skipping.\n",
      "RandomForest has already been trained with sampling strategy 0.2. Skipping.\n",
      "Checkpoint saved successfully at ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_results.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has already been trained with sampling strategy 0.3. Skipping.\n",
      "SVM has already been trained with sampling strategy 0.3. Skipping.\n",
      "XGBoost has already been trained with sampling strategy 0.3. Skipping.\n",
      "CatBoost has already been trained with sampling strategy 0.3. Skipping.\n",
      "LightGBM has already been trained with sampling strategy 0.3. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 90.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest has already been trained with sampling strategy 0.3. Skipping.\n",
      "Checkpoint saved successfully at ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_results.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 121.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has already been trained with sampling strategy 0.4. Skipping.\n",
      "SVM has already been trained with sampling strategy 0.4. Skipping.\n",
      "XGBoost has already been trained with sampling strategy 0.4. Skipping.\n",
      "CatBoost has already been trained with sampling strategy 0.4. Skipping.\n",
      "LightGBM has already been trained with sampling strategy 0.4. Skipping.\n",
      "RandomForest has already been trained with sampling strategy 0.4. Skipping.\n",
      "Checkpoint saved successfully at ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/RUS-sampling_strategies_models_fitted_with_best_parameters_results.pkl\n",
      "Models saved in ../models/models_fitted/RUS-sampling_strategies_models_fitted_with_best_parameters.pkl\n"
     ]
    }
   ],
   "source": [
    "# Dictionnaire des modèles\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, verbose=-1),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Paramètres de sous-échantillonnage à tester\n",
    "sampling_strategies = [0.1, 0.2, 0.3, 0.4]\n",
    "model_name_in_folder = \"RUS-sampling_strategies_models_fitted_with_best_parameters\"\n",
    "\n",
    "# Charger les modèles et résultats sauvegardés\n",
    "trained_models_rus, results = load_checkpoint_model(checkpoint_dir=checkpoint_dir, model_name_in_folder=model_name_in_folder)\n",
    "\n",
    "# Boucle sur les taux de sous-échantillonnage\n",
    "for sampling_strategy in sampling_strategies:\n",
    "    # Appliquer le sous-échantillonnage\n",
    "    rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Dictionnaire pour stocker les performances des modèles\n",
    "    model_performance = {}\n",
    "    models_dict = {}\n",
    "\n",
    "    # Boucle sur les modèles\n",
    "    for model_name, model in tqdm(models.items()):\n",
    "        # Vérifiez si le modèle a déjà été entraîné pour cette stratégie d'échantillonnage\n",
    "        if (\n",
    "            str(sampling_strategy) in trained_models_rus and \n",
    "            model_name in trained_models_rus[str(sampling_strategy)]\n",
    "        ):\n",
    "            print(f\"{model_name} has already been trained with sampling strategy {sampling_strategy}. Skipping.\")\n",
    "            # Charger le modèle entraîné depuis le dictionnaire\n",
    "            models_dict[model_name] = trained_models_rus[str(sampling_strategy)][model_name]\n",
    "            # Évaluer le modèle sans le réentraîner\n",
    "            y_pred = models_dict[model_name].predict(X_test)\n",
    "            y_prob = models_dict[model_name].predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            # Entraîner le modèle\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Prédire sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]  # Probabilité de la classe positive\n",
    "\n",
    "            # Stocker le modèle entraîné\n",
    "            models_dict[model_name] = model\n",
    "\n",
    "        # Évaluer le modèle\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        f1_score_ = report['1']['f1-score']  # F1-score pour la classe positive\n",
    "        recall_ = report['1']['recall']      # Rappel pour la classe positive\n",
    "\n",
    "        # Calcul de la courbe de précision-rappel\n",
    "        precision, recall_curve, _ = precision_recall_curve(y_test, y_prob)\n",
    "        auc_pr = auc(recall_curve, precision)  # AUC-PR\n",
    "\n",
    "        # Stocker les performances\n",
    "        model_performance[model_name] = {\n",
    "            'F1 Score': f1_score_,\n",
    "            'Recall': recall_,\n",
    "            'AUC PR': auc_pr\n",
    "        }\n",
    "\n",
    "    # Enregistrer les performances pour ce taux de sous-échantillonnage\n",
    "    results[str(sampling_strategy)] = model_performance\n",
    "    trained_models_rus[str(sampling_strategy)] = models_dict\n",
    "    # Sauvegarder les checkpoints après chaque stratégie\n",
    "    save_checkpoint(checkpoint_dir, model_name_in_folder, trained_models_rus, results)\n",
    "\n",
    "# Sauvegarde finale du dictionnaire des modèles\n",
    "save_final_model(\"../models/models_fitted/\", model_name_in_folder, trained_models_rus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Smote with StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_sm = {}\n",
    "results_sm = {}\n",
    "\n",
    "# Dictionnaire des modèles\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    #\"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Paramètres de recherche pour SMOTE et les modèles\n",
    "param_grids = {\n",
    "    'KNN': {\n",
    "        'smote__sampling_strategy': [0.1, 0.3, 0.5],\n",
    "        'smote__k_neighbors': [3, 5, 7],\n",
    "        'model__n_neighbors': [3, 5, 7],\n",
    "        'model__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    #'SVM': {\n",
    "    #    'smote__sampling_strategy': [0.1, 0.3, 0.5],\n",
    "    #    'smote__k_neighbors': [3, 5],\n",
    "    #    'model__C': [0.1, 1, 10],\n",
    "    #    'model__kernel': ['linear', 'rbf']\n",
    "    #},\n",
    "    'XGBoost': {\n",
    "        'smote__sampling_strategy': [0.1, 0.3, 0.5],\n",
    "        'smote__k_neighbors': [3, 5],\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'smote__sampling_strategy': [0.1, 0.3, 0.5],\n",
    "        'smote__k_neighbors': [3, 5],\n",
    "        'model__iterations': [100, 200],\n",
    "        'model__depth': [4, 6],\n",
    "        'model__learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'smote__sampling_strategy': [0.1, 0.3, 0.5],\n",
    "        'smote__k_neighbors': [3, 5],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [None, 10],\n",
    "        'model__min_samples_split': [2, 5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from ../models/checkpoints/SMOTE+models_fitted_with_best_parameters_checkpoint.pkl and ../models/checkpoints/SMOTE+models_fitted_with_best_parameters_results.pkl\n",
      "KNN has already been trained. Skipping.\n",
      "XGBoost has already been trained. Skipping.\n",
      "CatBoost has already been trained. Skipping.\n",
      "RandomForest has already been trained. Skipping.\n",
      "End of training.\n",
      "Models saved in ../models/models_fitted/SMOTE+models_fitted_with_best_parameters.pkl\n"
     ]
    }
   ],
   "source": [
    "model_name_in_folder = \"SMOTE+models_fitted_with_best_parameters\"\n",
    "best_models_sm, results_sm = load_checkpoint_model(checkpoint_dir=checkpoint_dir, model_name_in_folder=model_name_in_folder)\n",
    "\n",
    "# Séparation des données en entraînement et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Validation croisée avec StratifiedKFold (5-folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Pour chaque modèle, exécuter GridSearchCV et collecter les meilleurs modèles\n",
    "for model_name, model in models.items() :\n",
    "    if model_name in best_models_sm :\n",
    "        print(f\"{model_name} has already been trained. Skipping.\")\n",
    "        continue  # On passe au modèle suivant\n",
    "    \n",
    "\n",
    "    print(f\"Training for {model_name}\")\n",
    "    # Pipeline avec SMOTE appliqué uniquement aux données d'entraînement\n",
    "    pipeline = imPipeline([\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Définir les scores à optimiser\n",
    "    scorers = {\n",
    "        'F1': make_scorer(f1_score, pos_label=1),\n",
    "        'Recall': make_scorer(recall_score, pos_label=1)\n",
    "    }\n",
    "    \n",
    "    # GridSearchCV avec validation croisée StratifiedKFold\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grids[model_name],\n",
    "        cv=skf,  # Validation croisée avec StratifiedKFold\n",
    "        scoring=scorers,\n",
    "        refit='F1',  # Optimisation par F1-score\n",
    "        n_jobs=-1,  # Utilisation de tous les CPU disponibles\n",
    "        error_score='raise'  # Pour obtenir plus de détails sur les erreurs\n",
    "    )\n",
    "    \n",
    "    # Entraînement du modèle avec GridSearchCV sur les données d'entraînement\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Meilleur modèle\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Évaluation du modèle sur le jeu de test (non suréchantillonné)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcul des métriques sur les données de test\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision, recall_curve, _ = precision_recall_curve(y_test, y_prob)\n",
    "    auc_pr = auc(recall_curve, precision)\n",
    "    \n",
    "    # Enregistrer le modèle et ses performances dans le dictionnaire\n",
    "    best_models_sm[model_name] = best_model\n",
    "    \n",
    "    # Enregistrer les résultats et les meilleurs paramètres\n",
    "    results_sm[model_name] = {\n",
    "        'best_params': best_params,\n",
    "        'F1 Score': f1,\n",
    "        'Recall': recall,\n",
    "        'AUC PR': auc_pr\n",
    "    }\n",
    "    save_checkpoint(checkpoint_dir, model_name_in_folder, best_models_sm, results_sm)\n",
    "print(\"End of training.\")\n",
    "# Sauvegarde finale du dictionnaire des modèles\n",
    "save_final_model(\"../models/models_fitted/\", model_name_in_folder, best_models_sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
